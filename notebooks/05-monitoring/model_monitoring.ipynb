{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 모니터링\n",
    "\n",
    "이 노트북은 프로덕션 환경에서 머신러닝 모델의 성능을 모니터링하는 방법을 보여줍니다.\n",
    "\n",
    "## 학습 내용\n",
    "- 모델 성능 메트릭 추적\n",
    "- 데이터 드리프트 감지\n",
    "- 예측 분포 모니터링\n",
    "- 알림 및 대시보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install -q scikit-learn pandas numpy matplotlib seaborn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 플롯 설정\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기준 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 학습/테스트 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 모델 학습\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 초기 성능 측정\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred)\n",
    "baseline_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "baseline_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "baseline_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"기준 모델 성능:\")\n",
    "print(f\"Accuracy: {baseline_accuracy:.4f}\")\n",
    "print(f\"Precision: {baseline_precision:.4f}\")\n",
    "print(f\"Recall: {baseline_recall:.4f}\")\n",
    "print(f\"F1 Score: {baseline_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시간에 따른 성능 모니터링 시뮬레이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간에 따른 성능 변화 시뮬레이션\n",
    "np.random.seed(42)\n",
    "n_periods = 30  # 30일\n",
    "\n",
    "# 메트릭 저장\n",
    "performance_history = {\n",
    "    'day': [],\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': [],\n",
    "    'prediction_count': []\n",
    "}\n",
    "\n",
    "for day in range(1, n_periods + 1):\n",
    "    # 데이터 드리프트 시뮬레이션 (15일 이후 성능 저하)\n",
    "    if day > 15:\n",
    "        # 노이즈 추가로 성능 저하 시뮬레이션\n",
    "        noise = np.random.normal(0, 0.3, X_test_scaled.shape)\n",
    "        X_test_noisy = X_test_scaled + noise * (day - 15) / 15\n",
    "    else:\n",
    "        X_test_noisy = X_test_scaled\n",
    "    \n",
    "    # 예측\n",
    "    y_pred_day = model.predict(X_test_noisy)\n",
    "    \n",
    "    # 메트릭 계산\n",
    "    acc = accuracy_score(y_test, y_pred_day)\n",
    "    prec = precision_score(y_test, y_pred_day, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_day, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_day, average='weighted')\n",
    "    \n",
    "    # 기록\n",
    "    performance_history['day'].append(day)\n",
    "    performance_history['accuracy'].append(acc)\n",
    "    performance_history['precision'].append(prec)\n",
    "    performance_history['recall'].append(rec)\n",
    "    performance_history['f1_score'].append(f1)\n",
    "    performance_history['prediction_count'].append(len(y_test))\n",
    "\n",
    "# 데이터프레임 생성\n",
    "perf_df = pd.DataFrame(performance_history)\n",
    "print(\"성능 히스토리:\")\n",
    "print(perf_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 메트릭 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Model Performance Over Time', fontsize=16)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(perf_df['day'], perf_df['accuracy'], marker='o')\n",
    "axes[0, 0].axhline(y=baseline_accuracy, color='r', linestyle='--', label='Baseline')\n",
    "axes[0, 0].axhline(y=baseline_accuracy * 0.95, color='orange', linestyle='--', label='Alert Threshold (95%)')\n",
    "axes[0, 0].set_xlabel('Day')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].set_title('Accuracy Over Time')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[0, 1].plot(perf_df['day'], perf_df['precision'], marker='o', color='green')\n",
    "axes[0, 1].axhline(y=baseline_precision, color='r', linestyle='--', label='Baseline')\n",
    "axes[0, 1].set_xlabel('Day')\n",
    "axes[0, 1].set_ylabel('Precision')\n",
    "axes[0, 1].set_title('Precision Over Time')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 0].plot(perf_df['day'], perf_df['recall'], marker='o', color='purple')\n",
    "axes[1, 0].axhline(y=baseline_recall, color='r', linestyle='--', label='Baseline')\n",
    "axes[1, 0].set_xlabel('Day')\n",
    "axes[1, 0].set_ylabel('Recall')\n",
    "axes[1, 0].set_title('Recall Over Time')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[1, 1].plot(perf_df['day'], perf_df['f1_score'], marker='o', color='red')\n",
    "axes[1, 1].axhline(y=baseline_f1, color='r', linestyle='--', label='Baseline')\n",
    "axes[1, 1].set_xlabel('Day')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].set_title('F1 Score Over Time')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 드리프트 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_drift_ks_test(reference_data, current_data, feature_names, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Kolmogorov-Smirnov 테스트를 사용한 데이터 드리프트 감지\n",
    "    \"\"\"\n",
    "    drift_detected = {}\n",
    "    \n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        # KS 테스트\n",
    "        statistic, pvalue = stats.ks_2samp(\n",
    "            reference_data[:, i],\n",
    "            current_data[:, i]\n",
    "        )\n",
    "        \n",
    "        # 드리프트 감지 (p-value가 threshold보다 작으면 드리프트)\n",
    "        is_drift = pvalue < threshold\n",
    "        \n",
    "        drift_detected[feature_name] = {\n",
    "            'drift': is_drift,\n",
    "            'statistic': statistic,\n",
    "            'pvalue': pvalue\n",
    "        }\n",
    "    \n",
    "    return drift_detected\n",
    "\n",
    "# 드리프트가 있는 데이터 생성 (노이즈 추가)\n",
    "X_drifted = X_test + np.random.normal(0, 0.5, X_test.shape)\n",
    "\n",
    "# 드리프트 감지\n",
    "drift_results = detect_drift_ks_test(\n",
    "    X_train,\n",
    "    X_drifted,\n",
    "    iris.feature_names\n",
    ")\n",
    "\n",
    "print(\"데이터 드리프트 감지 결과:\")\n",
    "print(\"=\" * 60)\n",
    "for feature, result in drift_results.items():\n",
    "    status = \"⚠️ DRIFT DETECTED\" if result['drift'] else \"✓ No drift\"\n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"  Status: {status}\")\n",
    "    print(f\"  P-value: {result['pvalue']:.4f}\")\n",
    "    print(f\"  Statistic: {result['statistic']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 분포 비교 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Feature Distribution Comparison (Train vs Drifted)', fontsize=16)\n",
    "\n",
    "for idx, (ax, feature_name) in enumerate(zip(axes.flatten(), iris.feature_names)):\n",
    "    # 히스토그램\n",
    "    ax.hist(X_train[:, idx], bins=20, alpha=0.5, label='Training Data', density=True)\n",
    "    ax.hist(X_drifted[:, idx], bins=20, alpha=0.5, label='Current Data', density=True)\n",
    "    \n",
    "    # 드리프트 상태 표시\n",
    "    drift_status = \"DRIFT\" if drift_results[feature_name]['drift'] else \"OK\"\n",
    "    ax.set_title(f'{feature_name} [{drift_status}]')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 예측 분포 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간에 따른 예측 분포 시뮬레이션\n",
    "prediction_history = []\n",
    "\n",
    "for day in range(1, 31):\n",
    "    # 데이터 변화 시뮬레이션\n",
    "    if day > 15:\n",
    "        noise = np.random.normal(0, 0.3, X_test_scaled.shape)\n",
    "        X_current = X_test_scaled + noise * (day - 15) / 15\n",
    "    else:\n",
    "        X_current = X_test_scaled\n",
    "    \n",
    "    # 예측\n",
    "    predictions = model.predict(X_current)\n",
    "    \n",
    "    # 각 클래스의 예측 비율\n",
    "    for pred_class in range(3):\n",
    "        count = np.sum(predictions == pred_class)\n",
    "        prediction_history.append({\n",
    "            'day': day,\n",
    "            'class': iris.target_names[pred_class],\n",
    "            'count': count,\n",
    "            'percentage': count / len(predictions) * 100\n",
    "        })\n",
    "\n",
    "pred_df = pd.DataFrame(prediction_history)\n",
    "\n",
    "# 예측 분포 시각화\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for class_name in iris.target_names:\n",
    "    class_data = pred_df[pred_df['class'] == class_name]\n",
    "    plt.plot(class_data['day'], class_data['percentage'], \n",
    "             marker='o', label=class_name)\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Prediction Percentage (%)')\n",
    "plt.title('Prediction Distribution Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 알림 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_health(current_metrics, baseline_metrics, thresholds):\n",
    "    \"\"\"\n",
    "    모델 상태 확인 및 알림 생성\n",
    "    \"\"\"\n",
    "    alerts = []\n",
    "    \n",
    "    for metric_name, current_value in current_metrics.items():\n",
    "        baseline_value = baseline_metrics.get(metric_name)\n",
    "        threshold = thresholds.get(metric_name, 0.95)\n",
    "        \n",
    "        if baseline_value is not None:\n",
    "            # 임계값 확인\n",
    "            if current_value < baseline_value * threshold:\n",
    "                degradation = ((baseline_value - current_value) / baseline_value) * 100\n",
    "                alerts.append({\n",
    "                    'metric': metric_name,\n",
    "                    'severity': 'HIGH' if degradation > 10 else 'MEDIUM',\n",
    "                    'message': f\"{metric_name} degraded by {degradation:.2f}%\",\n",
    "                    'current': current_value,\n",
    "                    'baseline': baseline_value\n",
    "                })\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "# 기준 메트릭\n",
    "baseline_metrics = {\n",
    "    'accuracy': baseline_accuracy,\n",
    "    'precision': baseline_precision,\n",
    "    'recall': baseline_recall,\n",
    "    'f1_score': baseline_f1\n",
    "}\n",
    "\n",
    "# 임계값 설정 (기준값의 95%)\n",
    "thresholds = {\n",
    "    'accuracy': 0.95,\n",
    "    'precision': 0.95,\n",
    "    'recall': 0.95,\n",
    "    'f1_score': 0.95\n",
    "}\n",
    "\n",
    "# 최근 성능 (30일차)\n",
    "recent_metrics = {\n",
    "    'accuracy': perf_df.iloc[-1]['accuracy'],\n",
    "    'precision': perf_df.iloc[-1]['precision'],\n",
    "    'recall': perf_df.iloc[-1]['recall'],\n",
    "    'f1_score': perf_df.iloc[-1]['f1_score']\n",
    "}\n",
    "\n",
    "# 상태 확인\n",
    "alerts = check_model_health(recent_metrics, baseline_metrics, thresholds)\n",
    "\n",
    "print(\"모델 상태 알림:\")\n",
    "print(\"=\" * 70)\n",
    "if alerts:\n",
    "    for alert in alerts:\n",
    "        print(f\"\\n[{alert['severity']}] {alert['message']}\")\n",
    "        print(f\"  Current: {alert['current']:.4f}\")\n",
    "        print(f\"  Baseline: {alert['baseline']:.4f}\")\nelse:\n",
    "    print(\"✓ 모든 메트릭이 정상 범위 내에 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모니터링 대시보드 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대시보드 요약 생성\n",
    "def generate_monitoring_summary(perf_df, drift_results, alerts):\n",
    "    summary = {\n",
    "        'monitoring_period': f\"{perf_df['day'].min()} - {perf_df['day'].max()} days\",\n",
    "        'total_predictions': perf_df['prediction_count'].sum(),\n",
    "        'avg_accuracy': perf_df['accuracy'].mean(),\n",
    "        'current_accuracy': perf_df.iloc[-1]['accuracy'],\n",
    "        'accuracy_trend': 'decreasing' if perf_df['accuracy'].iloc[-1] < perf_df['accuracy'].iloc[0] else 'stable/increasing',\n",
    "        'drift_detected': sum(1 for r in drift_results.values() if r['drift']),\n",
    "        'total_features': len(drift_results),\n",
    "        'active_alerts': len(alerts),\n",
    "        'alert_severity': [a['severity'] for a in alerts]\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "summary = generate_monitoring_summary(perf_df, drift_results, alerts)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"모니터링 대시보드 요약\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"모니터링 기간: {summary['monitoring_period']}\")\n",
    "print(f\"총 예측 수: {summary['total_predictions']:,}\")\n",
    "print(f\"평균 정확도: {summary['avg_accuracy']:.4f}\")\n",
    "print(f\"현재 정확도: {summary['current_accuracy']:.4f}\")\n",
    "print(f\"정확도 추세: {summary['accuracy_trend']}\")\n",
    "print(f\"드리프트 감지: {summary['drift_detected']}/{summary['total_features']} features\")\n",
    "print(f\"활성 알림: {summary['active_alerts']}\")\n",
    "if summary['active_alerts'] > 0:\n",
    "    print(f\"알림 심각도: {', '.join(summary['alert_severity'])}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "이 노트북에서는 프로덕션 환경의 모델 모니터링에 대해 학습했습니다:\n",
    "1. ✅ 시간에 따른 모델 성능 추적\n",
    "2. ✅ 데이터 드리프트 감지 (Kolmogorov-Smirnov 테스트)\n",
    "3. ✅ 예측 분포 모니터링\n",
    "4. ✅ 알림 시스템 구현\n",
    "5. ✅ 모니터링 대시보드 요약\n",
    "\n",
    "**모니터링 모범 사례:**\n",
    "- 기준 메트릭 설정 및 추적\n",
    "- 정기적인 데이터 드리프트 확인\n",
    "- 성능 저하 시 자동 알림\n",
    "- 예측 분포 변화 모니터링\n",
    "- 정기적인 모델 재학습 고려\n",
    "\n",
    "다음 단계: CI/CD 파이프라인 구축"
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
