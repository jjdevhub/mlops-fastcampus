{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow를 활용한 실험 추적\n",
    "\n",
    "이 노트북은 MLflow를 사용하여 머신러닝 실험을 추적하고 관리하는 방법을 보여줍니다.\n",
    "\n",
    "## 학습 내용\n",
    "- MLflow 설정\n",
    "- 실험 생성 및 실행\n",
    "- 하이퍼파라미터 및 메트릭 로깅\n",
    "- 모델 저장 및 관리\n",
    "- 실험 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install -q mlflow scikit-learn pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"MLflow 버전: {mlflow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine 데이터셋 로드\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# 학습/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"학습 데이터: {X_train_scaled.shape}\")\n",
    "print(f\"테스트 데이터: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MLflow 실험 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험 이름 설정\n",
    "experiment_name = \"wine-classification\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"실험 이름: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 단일 실험 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest로 단일 실험 실행\n",
    "with mlflow.start_run(run_name=\"rf-baseline\"):\n",
    "    # 파라미터 설정\n",
    "    params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # 파라미터 로깅\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # 모델 학습\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 예측\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # 메트릭 계산 및 로깅\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    \n",
    "    # 모델 저장\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 여러 모델 비교 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 모델 정의\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# 각 모델에 대해 실험 실행\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=f\"{model_name.lower()}\"):\n",
    "        # 모델 이름 로깅\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        \n",
    "        # 모델 파라미터 로깅\n",
    "        for param, value in model.get_params().items():\n",
    "            mlflow.log_param(param, value)\n",
    "        \n",
    "        # 모델 학습\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # 예측\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # 메트릭 계산\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # 메트릭 로깅\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        \n",
    "        # 모델 저장\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # 결과 저장\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# 결과를 데이터프레임으로 변환\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n모델 비교 결과:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 하이퍼파라미터 튜닝 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest의 다양한 하이퍼파라미터 조합 시도\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "tuning_results = []\n",
    "\n",
    "for n_est in param_grid['n_estimators']:\n",
    "    for max_d in param_grid['max_depth']:\n",
    "        with mlflow.start_run(run_name=f\"rf-tune-n{n_est}-d{max_d}\"):\n",
    "            # 파라미터 로깅\n",
    "            mlflow.log_param(\"n_estimators\", n_est)\n",
    "            mlflow.log_param(\"max_depth\", max_d)\n",
    "            mlflow.log_param(\"model_type\", \"RandomForest\")\n",
    "            \n",
    "            # 모델 학습\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=max_d,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # 예측 및 평가\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            # 메트릭 로깅\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"f1_score\", f1)\n",
    "            \n",
    "            # 모델 저장\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "            \n",
    "            tuning_results.append({\n",
    "                'n_estimators': n_est,\n",
    "                'max_depth': max_d,\n",
    "                'accuracy': accuracy,\n",
    "                'f1_score': f1\n",
    "            })\n",
    "\n",
    "# 결과 시각화\n",
    "tuning_df = pd.DataFrame(tuning_results)\n",
    "print(\"\\n하이퍼파라미터 튜닝 결과:\")\n",
    "print(tuning_df.sort_values('accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 파라미터 찾기\n",
    "best_params = tuning_df.loc[tuning_df['accuracy'].idxmax()]\n",
    "print(\"\\n최적 하이퍼파라미터:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 아티팩트 로깅 (차트, 데이터 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"rf-with-artifacts\"):\n",
    "    # 모델 학습\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 예측 및 평가\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 메트릭 로깅\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # 특성 중요도 차트 생성\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': wine.feature_names,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['feature'][:10], feature_importance['importance'][:10])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 10 Feature Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 차트를 아티팩트로 로깅\n",
    "    mlflow.log_artifact('feature_importance.png')\n",
    "    \n",
    "    # 모델 저장\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    print(f\"아티팩트가 로깅되었습니다. Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 저장된 모델 로드 및 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험에서 최고 성능의 run ID 찾기\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if len(runs) > 0:\n",
    "    best_run_id = runs.iloc[0]['run_id']\n",
    "    best_accuracy = runs.iloc[0]['metrics.accuracy']\n",
    "    \n",
    "    print(f\"최고 성능 Run ID: {best_run_id}\")\n",
    "    print(f\"최고 Accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    # 모델 로드\n",
    "    model_uri = f\"runs:/{best_run_id}/model\"\n",
    "    loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = loaded_model.predict(X_test_scaled[:5])\n",
    "    print(\"\\n로드된 모델의 예측:\")\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"샘플 {i+1}: {wine.target_names[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 실험 결과 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 실험 결과 조회\n",
    "all_runs = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.accuracy DESC\"]\n",
    ")\n",
    "\n",
    "# 주요 컬럼만 선택\n",
    "columns_to_show = ['run_id', 'metrics.accuracy', 'metrics.f1_score', \n",
    "                   'params.model_type', 'params.n_estimators', 'params.max_depth']\n",
    "display_columns = [col for col in columns_to_show if col in all_runs.columns]\n",
    "\n",
    "print(\"\\n전체 실험 결과 (정확도 순):\")\n",
    "print(all_runs[display_columns].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "이 노트북에서는 MLflow를 사용하여:\n",
    "1. ✅ 실험 추적 환경 설정\n",
    "2. ✅ 단일 모델 실험 실행\n",
    "3. ✅ 여러 모델 비교 실험\n",
    "4. ✅ 하이퍼파라미터 튜닝 실험\n",
    "5. ✅ 아티팩트 (차트, 파일) 로깅\n",
    "6. ✅ 저장된 모델 로드 및 사용\n",
    "7. ✅ 실험 결과 조회 및 비교\n",
    "\n",
    "다음 단계: 모델 버전 관리 및 레지스트리 사용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
